import spacy
from spacy_streamlit import visualize_ner, visualize_tokens
from spacy.matcher import Matcher
import streamlit as st
import jieba

# Global setting
MODELS = {"ä¸­æ–‡(zh_core_web_sm)": "zh_core_web_sm", 
          "English(en_core_web_sm)": "en_core_web_sm", 
          "æ—¥æœ¬èª(ja_core_news_sm)": "ja_core_news_sm"}
models_to_display = list(MODELS.keys())
ZH_TEXT = "ï¼ˆä¸­å¤®ç¤¾ï¼‰ä¸­å¤®æµè¡Œç–«æƒ…æŒ‡æ®ä¸­å¿ƒå®£å¸ƒï¼Œä»Šå¤©åœ‹å…§æ–°å¢60ä¾‹COVID-19ï¼ˆ2019å† ç‹€ç—…æ¯’ç–¾ç—…ï¼‰ï¼Œåˆ†åˆ¥ç‚º49ä¾‹å¢ƒå¤–ç§»å…¥ï¼Œ11ä¾‹æœ¬åœŸç—…ä¾‹ï¼Œæ˜¯å»å¹´8æœˆ29æ—¥æœ¬åœŸæ–°å¢13ä¾‹ä»¥ä¾†çš„æ–°é«˜ï¼Œåˆæ­¥ç ”åˆ¤å…¶ä¸­10ä¾‹å€‹æ¡ˆçš†èˆ‡æ¡ƒåœ’æ©Ÿå ´ç–«æƒ…æœ‰é—œã€‚"
ZH_REGEX = "\d{2,4}"
EN_TEXT = "(CNN) Covid-19 hospitalization rates among children are soaring in the United States, with an average of 4.3 children under 5 per 100,000 hospitalized with an infection as of the week ending January 1, up from 2.6 children the previous week, according to data from the US Centers for Disease Control and Prevention. This represents a 48% increase from the week ending December 4, and the largest increase in hospitalization rate this age group has seen over the course of the pandemic."
EN_REGEX = "(ed|ing)$"
JA_TEXT = "ï¼ˆæœæ—¥æ–°èï¼‰æ–°å‹ã‚³ãƒ­ãƒŠã‚¦ã‚¤ãƒ«ã‚¹ã®å›½å†…æ„ŸæŸ“è€…ã¯9æ—¥ã€æ–°ãŸã«8249äººãŒç¢ºèªã•ã‚ŒãŸã€‚2æ—¥é€£ç¶šã§8åƒäººã‚’è¶…ãˆãŸã®ã¯æ˜¨å¹´9æœˆ11æ—¥ä»¥æ¥ã€ç´„4ã‚«æœˆã¶ã‚Šã€‚å…¨å›½çš„ã«æ„ŸæŸ“æ‹¡å¤§ãŒé€²ã‚€ä¸­ã€å¹´ã‚’ã¾ãŸã„ã 1é€±é–“ã®æ„ŸæŸ“è€…ã®éåŠæ•°ãŒ30ä»£ä»¥ä¸‹ã ã£ãŸã€‚ã‚³ãƒ­ãƒŠç‰¹æªæ³•ã«åŸºã¥ãã€Œã¾ã‚“å»¶é˜²æ­¢ç­‰é‡ç‚¹æªç½®ã€ãŒ9æ—¥ã‹ã‚‰é©ç”¨ã•ã‚ŒãŸ3çœŒã§ã¯ã€åºƒå³¶ã§éå»æœ€å¤šã®619äººãŒç¢ºèªã•ã‚ŒãŸã€‚"
JA_REGEX = "[ãŸã„]$"
DESCRIPTION = "spaCyè‡ªç„¶èªè¨€è™•ç†æ¨¡å‹å±•ç¤º"

st.set_page_config(
    page_icon="ğŸ¤ ",
    layout="wide",
)

# Model
st.markdown(f"# {DESCRIPTION}") 
st.markdown("## èªè¨€æ¨¡å‹") 
selected_model = st.radio("è«‹é¸æ“‡èªè¨€", models_to_display)
nlp = spacy.load(MODELS[selected_model])
nlp.add_pipe("merge_entities") 
st.markdown("---")

# Text
st.markdown("## å¾…åˆ†ææ–‡æœ¬") 
if selected_model == models_to_display[0]:
    default_text = ZH_TEXT
    default_regex = ZH_REGEX
elif selected_model == models_to_display[1]:
    default_text = EN_TEXT 
    default_regex = EN_REGEX 
elif selected_model == models_to_display[2]:
    default_text = JA_TEXT
    default_regex = JA_REGEX 

user_text = st.text_area("è«‹è¼¸å…¥æ–‡ç« ï¼š", default_text)
jieba_res = jieba.cut(user_text) 
jieba_res = "|".join(jieba_res)
st.write(f"Jieba: {jieba_res}")

doc = nlp(user_text)
spacy_res = [tok.text for tok in doc]
spacy_res = "|".join(spacy_res)
st.write(f"spaCy: {spacy_res}")
st.markdown("---")

# Pattern input
def show_one_token_attr(tok_num):
    pattern_types = ["æ­£å‰‡è¡¨é”", "å‘½åå¯¦é«”"]
    selected_info = st.radio("è«‹é¸æ“‡åŒ¹é…æ–¹å¼ï¼š", pattern_types, key="info_"+str(tok_num))
    if selected_info == pattern_types[0]:
        regex_text = st.text_input("è«‹è¼¸å…¥æ­£å‰‡è¡¨é”ï¼š", default_regex, key="regex_"+str(tok_num))
        pattern = [{'TEXT': {'REGEX': regex_text}}]
    elif selected_info == pattern_types[1]:
        ner_text = st.selectbox("è«‹é¸æ“‡å‘½åå¯¦é«”é¡åˆ¥ï¼š", ner_labels, key="ner_"+str(tok_num))
        pattern = [{'ENT_TYPE': ner_text}]
    return pattern 

# Two columns
left, right = st.columns(2)

with left:
    # Model output
    ner_labels = nlp.get_pipe("ner").labels
    visualize_ner(doc, labels=ner_labels, show_table=False, title="å‘½åå¯¦é«”")
    visualize_tokens(doc, attrs=["text", "pos_", "dep_", "ent_type_"], title="æ–·è©ç‰¹å¾µ")
    st.markdown("---")

with right:
    # Select num of tokens 
    selected_tok_nums = st.number_input("è«‹é¸æ“‡æ–·è©æ•¸é‡ï¼š", 1, 5, 1)
    st.markdown("---")

    # Select patterns
    patterns = []
    for tok_num in range(selected_tok_nums):
        pattern = show_one_token_attr(tok_num)
        patterns += pattern
    
    # Match the text with the selected patterns
    matcher = Matcher(nlp.vocab)
    matcher.add('Rule', [patterns])
    matches = matcher(doc, as_spans=True)

    # Output
    if matches:
        st.markdown("## è¦å‰‡åŒ¹é…çµæœï¼š")
        for span in matches:
            text = span.text
            left_toks = span.lefts
            left_texts = [t.text for t in left_toks]
            right_toks = span.rights
            right_texts = [t.text for t in right_toks]
            st.write(f"{left_texts} **{text}** {right_texts}")
    else:
        st.markdown("## æ²’æœ‰ä»»ä½•åŒ¹é…çµæœï¼")
