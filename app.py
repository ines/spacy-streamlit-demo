import spacy
from spacy_streamlit import visualize_ner, visualize_tokens
from spacy.matcher import Matcher
import streamlit as st

# Global setting
MODELS = {"ä¸­æ–‡": "zh_core_web_sm", 
          "English": "en_core_web_sm", 
          "æ—¥æœ¬èª": "ja_core_news_sm"}
models_to_display = list(MODELS.keys())
ZH_TEXT = "ç•¶æˆ‘æ­£æƒ³è‘—æˆ‘åˆ°åº•æœ‰æ²’æœ‰è¦‹éå­”å­çš„æ™‚å€™ï¼Œå­”å­å°±å‡ºç¾äº†ï¼"
ZH_REGEX = "[éäº†è‘—]"
DESCRIPTION = "spaCyè‡ªç„¶èªè¨€è™•ç†æ¨¡å‹å±•ç¤º"

st.set_page_config(
    page_icon="ğŸ¤ ",
    layout="wide",
)

# Model
st.markdown(f"# {DESCRIPTION}") 
st.markdown("## èªè¨€æ¨¡å‹") 
selected_model = st.radio("è«‹é¸æ“‡èªè¨€", models_to_display)
nlp = spacy.load(MODELS[selected_model])
nlp.add_pipe("merge_entities") 
st.markdown("---")

# Text
st.markdown("## å¾…åˆ†ææ–‡æœ¬") 
if selected_model == models_to_display[0]:
    default_text = ZH_TEXT
    default_regex = ZH_REGEX
elif selected_model == models_to_display[1]:
    default_text = ZH_TEXT # to be replaced
    default_regex = ZH_REGEX # to be replaced
elif selected_model == models_to_display[2]:
    default_text = ZH_TEXT # to be replaced
    default_regex = ZH_REGEX # to be replaced 

user_text = st.text_area("è«‹è¼¸å…¥æ–‡ç« ï¼š", default_text)
doc = nlp(user_text)
st.markdown("---")

# Pattern input
def show_one_token_attr(tok_num):
    pattern_types = ["æ­£å‰‡è¡¨é”", "å‘½åå¯¦é«”"]
    selected_info = st.radio("è«‹é¸æ“‡åŒ¹é…æ–¹å¼ï¼š", pattern_types, key="info_"+str(tok_num))
    if selected_info == pattern_types[0]:
        regex_text = st.text_input("è«‹è¼¸å…¥æ­£å‰‡è¡¨é”ï¼š", default_regex, key="regex_"+str(tok_num))
        pattern = [{'TEXT': {'REGEX': regex_text}}]
    elif selected_info == pattern_types[1]:
        ner_text = st.selectbox("è«‹é¸æ“‡å‘½åå¯¦é«”é¡åˆ¥ï¼š", ner_labels, key="ner_"+str(tok_num))
        pattern = [{'ENT_TYPE': ner_text}]
    return pattern 

# Two columns
left, right = st.columns(2)

with left:
    # Visualization
    ner_labels = nlp.get_pipe("ner").labels
    visualize_ner(doc, labels=ner_labels, show_table=False, title="å‘½åå¯¦é«”")
    visualize_tokens(doc, attrs=["text", "pos_", "dep_", "ent_type_"], title="æ–·è©ç‰¹å¾µ")
    st.markdown("---")

with right:
    # Num of tokens 
    selected_tok_nums = st.number_input("è«‹é¸æ“‡æ–·è©æ•¸é‡ï¼š", 1, 5, 2)
    st.markdown("---")

    # Selected patterns
    patterns = []
    for tok_num in range(selected_tok_nums):
        pattern = show_one_token_attr(tok_num)
        patterns += pattern
    
    # Matches
    matcher = Matcher(nlp.vocab)
    matcher.add('Rule', [patterns])
    matches = matcher(doc, as_spans=True)

    # Output
    if matches:
        st.markdown("## è¦å‰‡åŒ¹é…çµæœï¼š")
        for span in matches:
            text = span.text
            #left_tokens = span.lefts
            #left_chunks = [t.txt for t in left_tokens]
            #right_tokens = span.rights
            #right_chunks = [t.txt for t in right_tokens]
            st.markdown(f"### {text}")
    else:
        st.markdownn("## æ²’æœ‰ä»»ä½•åŒ¹é…çµæœï¼")
