import spacy
from spacy_streamlit import visualize_ner, visualize_tokens
from spacy.matcher import Matcher
import streamlit as st

# Global setting
MODELS = {"ä¸­æ–‡(zh_core_web_sm)": "zh_core_web_sm", 
          "English(en_core_web_sm)": "en_core_web_sm", 
          "æ—¥æœ¬èª(ja_core_news_sm)": "ja_core_news_sm"}
models_to_display = list(MODELS.keys())
ZH_TEXT = "ï¼ˆä¸­å¤®ç¤¾ï¼‰ä¸­äºåœ‹å®¶å“ˆè–©å…‹è¿‘æ—¥ç™¼ç”Ÿæ°‘çœ¾ç¤ºå¨æš´å‹•ï¼Œå¼•ç™¼æ”¿åºœåˆ‡æ–·ç¶²è·¯ï¼Œé€£å¸¶é€ æˆæ¯”ç‰¹å¹£åƒ¹æ ¼é‡æŒ«ï¼Œæ‘œç ´4è¬3000ç¾å…ƒé—œå¡ã€‚é€™ä¹Ÿå‡¸é¡¯åŠ å¯†è²¨å¹£æŒ–ç¤¦å¤§åœ‹å“ˆè–©å…‹åœ¨æ¯”ç‰¹å¹£ç”Ÿæ…‹åœˆåˆ†é‡èˆ‰è¶³è¼•é‡ã€‚"
ZH_REGEX = "\d{2,4}"
EN_TEXT = "(CNN) President Joe Biden on Thursday marked the first anniversary of the January 6 insurrection by forcefully calling out former President Donald Trump for attempting to undo American democracy, saying such an insurrection must never happen again."
EN_REGEX = "(ed|ing)"
JA_TEXT = "ï¼ˆæœæ—¥æ–°èï¼‰ç´™ã®æ•™ç§‘æ›¸ã‚’ãƒ‡ãƒ¼ã‚¿åŒ–ã—ãŸã€Œãƒ‡ã‚¸ã‚¿ãƒ«æ•™ç§‘æ›¸ã€ãŒæ–°å¹´åº¦ã‹ã‚‰ã€å…¨å°ä¸­å­¦æ ¡ã«ç„¡å„Ÿã§æä¾›ã•ã‚Œã‚‹ã€‚æ–‡éƒ¨ç§‘å­¦çœãŒã€2024å¹´åº¦ã®æœ¬æ ¼å°å…¥ã«å‘ã‘ãŸå®Ÿè¨¼äº‹æ¥­ã¨ã—ã¦å¤–å›½èªï¼ˆè‹±èªï¼‰ã§é…å¸ƒã—ã€å¸Œæœ›ã™ã‚‹å­¦æ ¡ã®ä¸€éƒ¨ã«ã¯ã€ã»ã‹ã®æ•™ç§‘ã‹ã‚‰ã‚‚1æ•™ç§‘åˆ†ã‚’æä¾›ã™ã‚‹ã€‚ç´™ã¨ã®ä½µå­˜ã‚„è²»ç”¨ã®ã‚ã‚Šæ–¹ãªã©ã«ã¤ã„ã¦èª²é¡Œã‚’æ´—ã„å‡ºã™ã€‚"
JA_REGEX = "[ãŒã§ã«]"
DESCRIPTION = "spaCyè‡ªç„¶èªè¨€è™•ç†æ¨¡å‹å±•ç¤º"

st.set_page_config(
    page_icon="ğŸ¤ ",
    layout="wide",
)

# Model
st.markdown(f"# {DESCRIPTION}") 
st.markdown("## èªè¨€æ¨¡å‹") 
selected_model = st.radio("è«‹é¸æ“‡èªè¨€", models_to_display)
nlp = spacy.load(MODELS[selected_model])
nlp.add_pipe("merge_entities") 
st.markdown("---")

# Text
st.markdown("## å¾…åˆ†ææ–‡æœ¬") 
if selected_model == models_to_display[0]:
    default_text = ZH_TEXT
    default_regex = ZH_REGEX
elif selected_model == models_to_display[1]:
    default_text = EN_TEXT 
    default_regex = EN_REGEX 
elif selected_model == models_to_display[2]:
    default_text = JA_TEXT
    default_regex = JA_REGEX 

user_text = st.text_area("è«‹è¼¸å…¥æ–‡ç« ï¼š", default_text)
doc = nlp(user_text)
st.markdown("---")

# Pattern input
def show_one_token_attr(tok_num):
    pattern_types = ["æ­£å‰‡è¡¨é”", "å‘½åå¯¦é«”"]
    selected_info = st.radio("è«‹é¸æ“‡åŒ¹é…æ–¹å¼ï¼š", pattern_types, key="info_"+str(tok_num))
    if selected_info == pattern_types[0]:
        regex_text = st.text_input("è«‹è¼¸å…¥æ­£å‰‡è¡¨é”ï¼š", default_regex, key="regex_"+str(tok_num))
        pattern = [{'TEXT': {'REGEX': regex_text}}]
    elif selected_info == pattern_types[1]:
        ner_text = st.selectbox("è«‹é¸æ“‡å‘½åå¯¦é«”é¡åˆ¥ï¼š", ner_labels, key="ner_"+str(tok_num))
        pattern = [{'ENT_TYPE': ner_text}]
    return pattern 

# Two columns
left, right = st.columns(2)

with left:
    # Model output
    ner_labels = nlp.get_pipe("ner").labels
    visualize_ner(doc, labels=ner_labels, show_table=False, title="å‘½åå¯¦é«”")
    visualize_tokens(doc, attrs=["text", "pos_", "dep_", "ent_type_"], title="æ–·è©ç‰¹å¾µ")
    st.markdown("---")

with right:
    # Select num of tokens 
    selected_tok_nums = st.number_input("è«‹é¸æ“‡æ–·è©æ•¸é‡ï¼š", 1, 5, 2)
    st.markdown("---")

    # Select patterns
    patterns = []
    for tok_num in range(selected_tok_nums):
        pattern = show_one_token_attr(tok_num)
        patterns += pattern
    
    # Match the text with the selected patterns
    matcher = Matcher(nlp.vocab)
    matcher.add('Rule', [patterns])
    matches = matcher(doc, as_spans=True)

    # Output
    if matches:
        st.markdown("## è¦å‰‡åŒ¹é…çµæœï¼š")
        for span in matches:
            text = span.text
            left_toks = span.lefts
            left_texts = [t.text for t in left_toks]
            right_toks = span.rights
            right_texts = [t.text for t in right_toks]
            st.write(f"{left_texts} **{text}** {right_texts}")
    else:
        st.markdown("## æ²’æœ‰ä»»ä½•åŒ¹é…çµæœï¼")
